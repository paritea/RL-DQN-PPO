# RL-DQN-PPO

An attempt at comparing DQN and PPO peformance and sample efficieny by trying them on 2 RL environments - Lunar Landing v2 and Cartpole v1.
